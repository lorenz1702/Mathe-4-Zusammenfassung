

\section{Wichtige diskrete Verteilungen}

\subsection{Binomialverteilung}

Seien $n$ eine natürliche Zahl und $0\leq p\leq 1$. Die zur Zähldichte

\[k\longrightarrow f(k)=\binom{n}{k}\cdot p^k\cdot (1-p)^{n-k},k=0,...,n, \]

gehörende Verteilung heißt \texttt{Binomialverteilung} mit den Parametern $n$ und $p$ und wird mit $Bin(n,p)$ bezeichnet.

\subsection{Poisson-Verteilung}

Ideales Zufallsexperiment mit kleiner Erfolgswahrscheinlichkeit $p$ werde $n$ mal in unabhängiger Folge durchführt ($n$ groß). Ist $X$ die zufällige Anzahl von Treffern, so gilt mit $\lambda := n\cdot p$ näherungsweise

\[\mathbb{P} (X=k) = \binom{n}{k}\cdot p^k \cdot (1-p)^{n-k}\thickapprox e^{-\lambda}\cdot \frac{\lambda^k}{k!}  \]

für $k\leq n$.

Wann es angewendet wird muss sic noc anescaut werden.

\section{Wichtige stetige Verteilung}

\subsection{Normalverteilung}

\[P(X\leq x)= F(x)=\Phi_{\mu ,\sigma ^2}(x)=\int_{x}^{-\infty} \frac{1}{\sigma\sqrt{2\pi}}\cdot 2^{-(x-\mu)^2/(2\sigma^2)} \,dx \]

Die Verteilungsfunktion $\Phi_{\mu ,\sigma ^2}(x)$ der Normalverteilung ist \textbf{nicht als geschlossene Funktion} darstellbar(d.h. ohne Integral oder unendliche Reihe). Für die Standardnormalverteilung ist sie tabelliert.

\[\Phi(-x)=1-\Phi(x)\]
Sei $X~\mathcal{N} (\mu,\sigma^2)$. Dann gilt

\[\mathbb{P} (X\leq t)=\Phi_{\mu ,\sigma ^2}(t)=\Phi\left( \frac{t-\mu}{\sigma} \right)\]

Beispiel: Sei$X~\mathcal{N} (2,9)$. Dann ist

\begin{align}
    P(1\leq X\leq 4)&=F_X(4)-F_X(1)\\
    &=\Phi\left(\frac{4-2}{\sqrt{9}}\right)-\Phi\left(\frac{1-2}{\sqrt{9} } \right)\\
    &=\Phi(0.67)-\Phi(-0.33)\\
    &=0.7486-(1-\Phi(0.33))\\
    &=0.7486-(1-0.6293)\\
    &=0.3779
\end{align}

Beispiel: Angenommen das Gewicht G der Studenten der DHBW Karlsruhe sei normalverteilt mit $\mu =75$kg und $\sigma=5$kg.\\

Bestimmen sie $P(69kg<G<81kg)$ rechnerisch mittels Tabelle.

\[P(69kg<G<81kg)=\Phi_{75,5^2}(81)-\Phi_{75,5^2}(69)\]

Zwei Studenten werden zufällig und unabhängig voneinander ausgewählt. Wie wahrscheinlich ist es das beide zwischen 69 und 81kg wiegen?
\begin{align}
    P(A)=P(B)&=76.9\%\textrm{ Ergebnis aus vorheriger Aufgabe}\\
    P(A\cap B)=P(A)\cdot P(B)&=0.769^2\thickapprox \underline{59.1\% }
\end{align}


\subsection{Exponential Verteilung}

Sollte in der 6 Vorlesung sein habe ich aber noch nicht gefunden.

\section{Übergangswahrscheinlichkeiten und bedingte Wahrscheinlichkeiten}

\subsection{Bedingte Wahrscheinlichkeit}
$(\Omega ,\mathcal{A} ,\mathbb{P} )$Wahrscheinlichkeitsraum,$A,B\in \mathcal{A} $ mit $\mathbb{P} (B)>0$. Dann heißt

\[\mathbb{P} (A|\footnote[1]{Der senkrechte Strich \dq|\dq steht also für \dq unter der Bedingung,dass\dq.}B):=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}\]

die bedingte Wahrscheinlichkeit von $A$ unter der Bedingung $B$.

\subsection{Gesetz der totalen Wahrscheinlichkeit}
Sind nur bedingte Wahrscheinlichkeiten und die Wahrscheinlichkeiten des bedingenden Ereignisses bekannt, ergibt sich dei totale Wahrscheinlichkeit von $A$ aus

\[P(A) = P(A|B)\cdot P(B)+P(A|B^c)\cdot P(B^c)\]
wobei $B^c$ das Gegenereignis zu $B$ bezeichnet.

\subsection{Satz von Bayes}
Für den Zusammenhang zwischen $P(A|B)$ und $P(B|A)$ ergibt sich direkt aus der Definition und der Multiplikationssatz der Satz von Bayes:

\[P(A|B)=\frac{P(A\cap B)}{P(B)}=\frac{P(B\cap A)}{P(B)}=\frac{P(B|A)\cdot P(A)}{P(B)}\].

Dabei kann $P(B)$ im Nenner mit Hilfe des Gesetzes der totalen Wahrscheinlichkeit berechnet werden.